{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXDHW_mjXtMp"
   },
   "source": [
    "# Mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20999,
     "status": "ok",
     "timestamp": 1615282633207,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "FvCyvU3wXU5i",
    "outputId": "1ebe457a-4d34-474b-ea70-4d9fd6765538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      " aimas2020\n",
      "'Automatic Generation of Topic Labels.gslides'\n",
      "'Colab Notebooks'\n",
      " cvdl2020\n",
      " iir_book.pdf\n",
      " ir_final\n",
      "'Medical AI'\n",
      "'Paper Slides'\n",
      " Q56094077\n",
      " res18_diabete_noaug.pth\n",
      "'Towards Better Text Understanding and Retrieval through Kernel Entity Saliency Modeling.gslides'\n",
      " tsai.ipynb\n",
      " 獎助學金\n",
      " 申請資料\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!ls /content/gdrive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7xdJXLgX6xs"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/gdrive/MyDrive/Q56094077/snrs/hw1_0319/hw1_data.zip -d /content/gdrive/MyDrive/Q56094077/snrs/hw1_0319"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNPvyQC_ZsBz"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 5086,
     "status": "ok",
     "timestamp": 1615282641207,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "R9e-OVDBZbU_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "executionInfo": {
     "elapsed": 776,
     "status": "error",
     "timestamp": 1615283001909,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "jUN8f3VP4u9D",
    "outputId": "9e4523ef-8226-4980-c086-f15bf7f0a33a"
   },
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch_geometric.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNGORK7aZz1P"
   },
   "source": [
    "# Define constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1615282784467,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "ynbCxisYZ2hy"
   },
   "outputs": [],
   "source": [
    "_root = os.getcwd()\n",
    "\n",
    "_data = os.path.join(_root, \"hw1_data\")\n",
    "\n",
    "data_synthetic = os.path.join(_data, \"Synthetic\", \"5000\")\n",
    "data_youtube = os.path.join(_data, \"youtube\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOu2CKff-W4B"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZdiko1lmiJy"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gU4XwwAu_WkR"
   },
   "source": [
    "- data.x\t节点特征，维度是[num_nodes, num_node_features]。\n",
    "- data.edge_index\t维度是[2, num_edges]，描述图中节点的关联关系，每一列对应的两个元素，分别是边的起点和重点。数据类型是torch.long。需要注意的是，data.edge_index是定义边的节点的张量（tensor），而不是节点的列表（list）。\n",
    "- data.edge_attr\t边的特征矩阵，维度是[num_edges, num_edge_features]\n",
    "- data.y\t训练目标（维度可以是任意的）。对于节点相关的任务，维度为[num_nodes, *]；对于图相关的任务，维度为[1,*]。\n",
    "- data.position\t节点位置矩阵（Node position matrix），维度为[num_nodes, num_dimensions]。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um9C8SFO_2Tx"
   },
   "source": [
    "- [Learning to Identify High Betweenness Centrality Nodes from\n",
    "Scratch: A Novel Graph Neural Network Approach](https://arxiv.org/pdf/1905.10418.pdf)\n",
    "- node initial feature = [$(d_v), 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5918,
     "status": "ok",
     "timestamp": 1615282793119,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "cxWp5RNpm1uL",
    "outputId": "4cf7bf3b-d143-4b96-eebb-2cd9c1b0f408"
   },
   "outputs": [],
   "source": [
    "synthetic = []\n",
    "between = []\n",
    "for f in os.listdir(data_synthetic):\n",
    "    if \"score\" in f:\n",
    "        # ground truth of betweenness centrality\n",
    "        p = os.path.join(data_synthetic, f)\n",
    "        between.append(p)\n",
    "    else:\n",
    "        p = os.path.join(data_synthetic, f)\n",
    "        synthetic.append(p)\n",
    "\n",
    "between.sort()\n",
    "synthetic.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "executionInfo": {
     "elapsed": 893,
     "status": "error",
     "timestamp": 1615282795672,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "GJrGQmiUxRGX",
    "outputId": "81d8b6cb-5008-47d8-baf4-1156d70e07fc"
   },
   "outputs": [],
   "source": [
    "batch = 1\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for index, f in enumerate(synthetic):\n",
    "    edge_index = torch_geometric.io.read_txt_array(f, dtype=torch.long)\n",
    "    edge_index = edge_index.t().contiguous()\n",
    "    edge_index = utils.to_undirected(edge_index)\n",
    "\n",
    "    row, col = edge_index  \n",
    "    deg = utils.degree(col) # must use col to get degree, why?\n",
    "    deg = deg.numpy()  \n",
    "\n",
    "    vertice = []\n",
    "    for d in deg:\n",
    "        vertice.append([d, 1, 1])\n",
    "    vertice = np.array(vertice, dtype=np.float)\n",
    "    vertice = torch.from_numpy(vertice)\n",
    "    \n",
    "    ### between centrality\n",
    "    bcs = []\n",
    "    bc = torch_geometric.io.read_txt_array(between[index], dtype=torch.double)\n",
    "    bc = bc.t().contiguous()\n",
    "    row, col = bc\n",
    "    bc = col\n",
    "    bc = bc.numpy()\n",
    "    for b in bc:\n",
    "        bcs.append([b])\n",
    "\n",
    "#     bcs = np.array(bcs)\n",
    "    data = Data(x=vertice, edge_index=edge_index, y=bcs)\n",
    "\n",
    "    data_list.append(data)\n",
    "\n",
    "loader = DataLoader(data_list, batch_size=batch)\n",
    "# print(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jh1T_INgi8Ql"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "gcEf-tUaqDVa"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "from torch_geometric.transforms import Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "error",
     "timestamp": 1615203940879,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "P5EzKoYr7SGL",
    "outputId": "5504fb67-0455-4af0-a697-930410895a70"
   },
   "outputs": [],
   "source": [
    "class Net(MessagePassing):\n",
    "    def __init__(self, c, p, q, num_layers, aggr=\"add\"):\n",
    "        super(Net, self).__init__(aggr=aggr)\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.w_0 = torch.nn.Linear(in_features=c, out_features=p).double()\n",
    "        \n",
    "        self.rnn = torch.nn.GRUCell(p, p).double()\n",
    "  \n",
    "        self.w_4 = torch.nn.Linear(in_features=p, out_features=q).double()\n",
    "        self.w_5 = torch.nn.Linear(in_features=q, out_features=1).double()\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # h_0 = x\n",
    "\n",
    "        # h_1\n",
    "        x = self.w_0(x)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        \n",
    "        row, col = edge_index\n",
    "        deg = utils.degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg = torch.add(deg, 1)\n",
    "        deg_inv_sqrt = torch.pow(deg, -0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        h_s = [x]\n",
    "        \n",
    "        \n",
    "        for i in range(self.num_layers-1):\n",
    "            # internally calls the message(), aggregate() and update() functions\n",
    "            m = self.propagate(edge_index, x=x, norm=norm)\n",
    "            x = self.rnn(m, x)\n",
    "            x = F.normalize(x, p=2, dim=1) \n",
    "           \n",
    "            h_s.append(x)\n",
    "        \n",
    "        h_s = torch.stack(h_s)\n",
    "#         print(h_s.shape)\n",
    "        z = global_max_pool(h_s, torch.tensor([0], dtype=torch.long).to(device))\n",
    "        \n",
    "        ### Decoder\n",
    "        z = self.w_4(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.w_5(z)\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def message(self, x_j, norm: OptTensor):\n",
    "        return x_j if norm is None else norm.view(-1, 1) * x_j\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvoodu8ki_Cu"
   },
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "id": "y5e6PdjwaGiM"
   },
   "outputs": [],
   "source": [
    "depth = 5\n",
    "p = 128 # embedding dimension of hidden state\n",
    "q = int(p/2)\n",
    "\n",
    "epochs = 1000\n",
    "model_save = os.path.join(_root, \"weight.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Net(c=3, p=p, q=q, num_layers=depth).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-4)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:39<04:15,  9.85s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "#     bce_loss = 0.0\n",
    "    graph_cnt = 0\n",
    "    for data in tqdm(loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data = data.to(device)\n",
    "        bc_pr = model(data)\n",
    "        bc_gt = data.y\n",
    "        bc_gt = np.array(bc_gt)\n",
    "        \n",
    "        picked = [(torch.rand(25000, 2) * 4999).long()]\n",
    "        for b in range(batch-1):\n",
    "            picked.append((torch.rand(25000, 2) * 4999).long())\n",
    "        \n",
    "        bce_loss = torch.tensor(0, dtype=torch.float).to(device)\n",
    "        for b in range(batch):\n",
    "            index = picked[b]\n",
    "            for i in range(len(index)):\n",
    "                s1, s2 = index[i]\n",
    "                \n",
    "                y_gt = bc_gt[b][s2] - bc_gt[b][s1]\n",
    "                y_pr = bc_pr[b][s2] - bc_pr[b][s1]\n",
    "                \n",
    "                y_gt = torch.from_numpy(y_gt).to(device)\n",
    "                loss = criterion(y_pr, y_gt)\n",
    "                bce_loss += loss\n",
    "                \n",
    "#         bce_loss += data.num_graphs * loss.item()\n",
    "        graph_cnt += data.num_graphs\n",
    "        \n",
    "        bce_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch = {}, loss = {}\".format(epoch, bce_loss.item()/graph_cnt))\n",
    "    \n",
    "    \n",
    "    checkpoint = {\n",
    "        'model_stat': model.state_dict(),\n",
    "        'optimizer_stat': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, model_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5000, 1])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test fit model\n",
    "predict = model(data.to(device))\n",
    "predict.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experiments, we randomly sample 5|V | source nodes and 5|V |\n",
    "target nodes with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25000, 2])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picked = (torch.rand(25000, 2) * 4999).long()\n",
    "for b in range(batch-1):\n",
    "    picked = torch.stack((picked, (torch.rand(25000, 2) * 4999).long()))\n",
    "    \n",
    "picked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[5000], edge_index=[2, 39964], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39962], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39960], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39966], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39966], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39968], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39964], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39968], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39964], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39962], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39968], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39962], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39960], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39966], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39964], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39964], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39962], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39968], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39964], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39968], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39966], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39964], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39966], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39964], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39968], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39962], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39968], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39966], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39966], x=[5000, 3], y=[1])\n",
      "Batch(batch=[5000], edge_index=[2, 39968], x=[5000, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "for data in loader:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-f652143d5d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'y'"
     ]
    }
   ],
   "source": [
    "(loader[0].y-loader.y[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
