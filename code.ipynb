{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXDHW_mjXtMp"
   },
   "source": [
    "# Mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20999,
     "status": "ok",
     "timestamp": 1615282633207,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "FvCyvU3wXU5i",
    "outputId": "1ebe457a-4d34-474b-ea70-4d9fd6765538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      " aimas2020\n",
      "'Automatic Generation of Topic Labels.gslides'\n",
      "'Colab Notebooks'\n",
      " cvdl2020\n",
      " iir_book.pdf\n",
      " ir_final\n",
      "'Medical AI'\n",
      "'Paper Slides'\n",
      " Q56094077\n",
      " res18_diabete_noaug.pth\n",
      "'Towards Better Text Understanding and Retrieval through Kernel Entity Saliency Modeling.gslides'\n",
      " tsai.ipynb\n",
      " 獎助學金\n",
      " 申請資料\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!ls /content/gdrive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7xdJXLgX6xs"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/gdrive/MyDrive/Q56094077/snrs/hw1_0319/hw1_data.zip -d /content/gdrive/MyDrive/Q56094077/snrs/hw1_0319"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNPvyQC_ZsBz"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 5086,
     "status": "ok",
     "timestamp": 1615282641207,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "R9e-OVDBZbU_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "executionInfo": {
     "elapsed": 776,
     "status": "error",
     "timestamp": 1615283001909,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "jUN8f3VP4u9D",
    "outputId": "9e4523ef-8226-4980-c086-f15bf7f0a33a"
   },
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch_geometric.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNGORK7aZz1P"
   },
   "source": [
    "# Define constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1615282784467,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "ynbCxisYZ2hy"
   },
   "outputs": [],
   "source": [
    "_root = os.getcwd()\n",
    "\n",
    "_data = os.path.join(_root, \"hw1_data\")\n",
    "\n",
    "data_synthetic = os.path.join(_data, \"Synthetic\", \"5000\")\n",
    "data_youtube = os.path.join(_data, \"youtube\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOu2CKff-W4B"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZdiko1lmiJy"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gU4XwwAu_WkR"
   },
   "source": [
    "- data.x\t节点特征，维度是[num_nodes, num_node_features]。\n",
    "- data.edge_index\t维度是[2, num_edges]，描述图中节点的关联关系，每一列对应的两个元素，分别是边的起点和重点。数据类型是torch.long。需要注意的是，data.edge_index是定义边的节点的张量（tensor），而不是节点的列表（list）。\n",
    "- data.edge_attr\t边的特征矩阵，维度是[num_edges, num_edge_features]\n",
    "- data.y\t训练目标（维度可以是任意的）。对于节点相关的任务，维度为[num_nodes, *]；对于图相关的任务，维度为[1,*]。\n",
    "- data.position\t节点位置矩阵（Node position matrix），维度为[num_nodes, num_dimensions]。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um9C8SFO_2Tx"
   },
   "source": [
    "- [Learning to Identify High Betweenness Centrality Nodes from\n",
    "Scratch: A Novel Graph Neural Network Approach](https://arxiv.org/pdf/1905.10418.pdf)\n",
    "- node initial feature = [$(d_v), 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5918,
     "status": "ok",
     "timestamp": 1615282793119,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "cxWp5RNpm1uL",
    "outputId": "4cf7bf3b-d143-4b96-eebb-2cd9c1b0f408"
   },
   "outputs": [],
   "source": [
    "synthetic = []\n",
    "between = []\n",
    "for f in os.listdir(data_synthetic):\n",
    "    if \"score\" in f:\n",
    "        # ground truth of betweenness centrality\n",
    "        p = os.path.join(data_synthetic, f)\n",
    "        between.append(p)\n",
    "    else:\n",
    "        p = os.path.join(data_synthetic, f)\n",
    "        synthetic.append(p)\n",
    "\n",
    "between.sort()\n",
    "synthetic.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "executionInfo": {
     "elapsed": 893,
     "status": "error",
     "timestamp": 1615282795672,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "GJrGQmiUxRGX",
    "outputId": "81d8b6cb-5008-47d8-baf4-1156d70e07fc"
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for index, f in enumerate(synthetic):\n",
    "    edge_index = torch_geometric.io.read_txt_array(f, dtype=torch.long)\n",
    "    edge_index = edge_index.t().contiguous()\n",
    "    edge_index = utils.to_undirected(edge_index)\n",
    "\n",
    "    row, col = edge_index  \n",
    "    deg = utils.degree(col) # must use col to get degree, why?\n",
    "    deg = deg.numpy()  \n",
    "\n",
    "    vertice = []\n",
    "    for d in deg:\n",
    "        vertice.append([d, 1, 1])\n",
    "    vertice = np.array(vertice, dtype=np.float)\n",
    "    vertice = torch.from_numpy(vertice)\n",
    "    \n",
    "    ### between centrality\n",
    "    bcs = []\n",
    "    bc = torch_geometric.io.read_txt_array(between[index], dtype=torch.long)\n",
    "    bc = bc.t().contiguous()\n",
    "    row, col = bc\n",
    "    bc = col\n",
    "    bc = bc.numpy()\n",
    "    for b in bc:\n",
    "        bcs.append([b])\n",
    "\n",
    "    data = Data(x=vertice, edge_index=edge_index, y=bcs)\n",
    "    \n",
    "    data_list.append(data)\n",
    "\n",
    "loader = DataLoader(data_list, batch_size=2)\n",
    "# print(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jh1T_INgi8Ql"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "gcEf-tUaqDVa"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "from torch_geometric.transforms import Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "error",
     "timestamp": 1615203940879,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "P5EzKoYr7SGL",
    "outputId": "5504fb67-0455-4af0-a697-930410895a70"
   },
   "outputs": [],
   "source": [
    "class Net(MessagePassing):\n",
    "    def __init__(self, c, p, q, num_layers, aggr=\"add\"):\n",
    "        super(Net, self).__init__(aggr=aggr)\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.w_0 = torch.nn.Linear(in_features=c, out_features=p).double()\n",
    "        \n",
    "        self.rnn = torch.nn.GRUCell(p, p).double()\n",
    "  \n",
    "        self.w_4 = torch.nn.Linear(in_features=p, out_features=q).double()\n",
    "        self.w_5 = torch.nn.Linear(in_features=q, out_features=1).double()\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # h_0 = x\n",
    "\n",
    "        # h_1\n",
    "        x = self.w_0(x)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        \n",
    "        row, col = edge_index\n",
    "        deg = utils.degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg = torch.add(deg, 1)\n",
    "        deg_inv_sqrt = torch.pow(deg, -0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        h_s = [x]\n",
    "        \n",
    "        \n",
    "        for i in range(self.num_layers-1):\n",
    "            # internally calls the message(), aggregate() and update() functions\n",
    "            m = self.propagate(edge_index, x=x, norm=norm)\n",
    "            x = self.rnn(m, x)\n",
    "            x = F.normalize(x, p=2, dim=1) \n",
    "           \n",
    "            h_s.append(x)\n",
    "        \n",
    "        h_s = torch.stack(h_s)\n",
    "        z = global_max_pool(h_s, torch.tensor([0], dtype=torch.long))\n",
    "        \n",
    "        ### Decoder\n",
    "        z = self.w_4(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.w_5(z)\n",
    "        \n",
    "        return ret\n",
    "\n",
    "    def message(self, x_j, norm: OptTensor):\n",
    "        return x_j if norm is None else norm.view(-1, 1) * x_j\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvoodu8ki_Cu"
   },
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "y5e6PdjwaGiM"
   },
   "outputs": [],
   "source": [
    "depth = 5\n",
    "p = 128 # embedding dimension of hidden state\n",
    "q = int(p/2)\n",
    "\n",
    "epochs = 100\n",
    "model_save = os.path.join(_root, \"weight.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Net(c=3, p=p, q=q, num_layers=depth).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-4)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 80.00 MiB (GPU 1; 22.17 GiB total capacity; 535.20 MiB already allocated; 46.81 MiB free; 630.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-6ba266f10b32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbc_pr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mbc_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-6ea34e240fc4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# internally calls the message(), aggregate() and update() functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoll_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;31m# For `GNNExplainer`, we require a separate message and aggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-6ea34e240fc4>\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, norm)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 1; 22.17 GiB total capacity; 535.20 MiB already allocated; 46.81 MiB free; 630.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    bce_loss = 0.0\n",
    "    graph_cnt = 0\n",
    "    for data in tqdm(loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data = data.to(device)\n",
    "        bc_pr = model(data)\n",
    "        bc_gt = data.y\n",
    "        \n",
    "        # row: source, col: det\n",
    "        row, col = data.edge_index\n",
    "        y_gt = bc_gt[col] - bc_gt[row]\n",
    "        y_pr = bc_pr[col] - bc_gt[row]\n",
    "        loss = criterion(y_pr, y_gt)\n",
    "        \n",
    "        bce_loss += data.num_graphs * loss.item()\n",
    "        graph_cnt += data.num_graphs\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch = {}, loss = {}\".format(epoch, bce_loss/graph_cnt))\n",
    "    \n",
    "    \n",
    "    checkpoint = {\n",
    "        'model_stat': model.state_dict(),\n",
    "        'optimizer_stat': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, model_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
