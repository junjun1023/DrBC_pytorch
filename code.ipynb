{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXDHW_mjXtMp"
   },
   "source": [
    "# Mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20999,
     "status": "ok",
     "timestamp": 1615282633207,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "FvCyvU3wXU5i",
    "outputId": "1ebe457a-4d34-474b-ea70-4d9fd6765538"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# !ls /content/gdrive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7xdJXLgX6xs"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/gdrive/MyDrive/Q56094077/snrs/hw1_0319/hw1_data.zip -d /content/gdrive/MyDrive/Q56094077/snrs/hw1_0319"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNPvyQC_ZsBz"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5086,
     "status": "ok",
     "timestamp": 1615282641207,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "R9e-OVDBZbU_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "executionInfo": {
     "elapsed": 776,
     "status": "error",
     "timestamp": 1615283001909,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "jUN8f3VP4u9D",
    "outputId": "9e4523ef-8226-4980-c086-f15bf7f0a33a"
   },
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch_geometric.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkit as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Setting:\n",
    "    _root = os.getcwd()\n",
    "\n",
    "    _data = os.path.join(_root, \"hw1_data\")\n",
    "\n",
    "    data_synthetic = os.path.join(_data, \"Synthetic\", \"5000\")\n",
    "    data_youtube = os.path.join(_data, \"youtube\")\n",
    "    \n",
    "    \n",
    "     # Create dir for train/test\n",
    "    date_time = datetime.strftime(datetime.now(), \"%Y-%m-%d %H-%M\")\n",
    "    root = os.path.join(_root, \"result\", date_time)\n",
    "    if os.path.exists(root):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(root)\n",
    "\n",
    "\n",
    "    ### Save plt info\n",
    "    train_info_p = os.path.join(root, \"train.json\")\n",
    "    val_info_p = os.path.join(root, \"valid.json\")\n",
    "    test_info_p = os.path.join(root, \"test.json\")\n",
    "\n",
    "    ### Save plt img\n",
    "    result_plt_p = os.path.join(root, \"train_plt.png\")\n",
    "    test_plt_p = os.path.join(root, \"test_plt.png\")\n",
    "    sum_box_p = os.path.join(root, \"sum_box.png\")\n",
    "        \n",
    "        \n",
    "    ### Data split\n",
    "    data_split = os.path.join(_root, \"split.json\")\n",
    "    \n",
    "\n",
    "    # Setting of training\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    mini_epochs = 500\n",
    "    epochs = 10000\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    weight_node2vec = os.path.join(root, \"node2vec.pth\")\n",
    "    weight_drbc = os.path.join(root, \"drbc.pth\")\n",
    "    \n",
    "    params_drbc = None\n",
    "    params_node2vec = None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = Setting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOu2CKff-W4B"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZdiko1lmiJy"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gU4XwwAu_WkR"
   },
   "source": [
    "- data.x\t节点特征，维度是[num_nodes, num_node_features]。\n",
    "- data.edge_index\t维度是[2, num_edges]，描述图中节点的关联关系，每一列对应的两个元素，分别是边的起点和重点。数据类型是torch.long。需要注意的是，data.edge_index是定义边的节点的张量（tensor），而不是节点的列表（list）。\n",
    "- data.edge_attr\t边的特征矩阵，维度是[num_edges, num_edge_features]\n",
    "- data.y\t训练目标（维度可以是任意的）。对于节点相关的任务，维度为[num_nodes, *]；对于图相关的任务，维度为[1,*]。\n",
    "- data.position\t节点位置矩阵（Node position matrix），维度为[num_nodes, num_dimensions]。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um9C8SFO_2Tx"
   },
   "source": [
    "- [Learning to Identify High Betweenness Centrality Nodes from\n",
    "Scratch: A Novel Graph Neural Network Approach](https://arxiv.org/pdf/1905.10418.pdf)\n",
    "- node initial feature = [$(d_v), 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5918,
     "status": "ok",
     "timestamp": 1615282793119,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "cxWp5RNpm1uL",
    "outputId": "4cf7bf3b-d143-4b96-eebb-2cd9c1b0f408"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "\n",
    "    edge_index = []\n",
    "    between = []\n",
    "    for f in os.listdir(path):\n",
    "        if \"score\" in f:\n",
    "            # ground truth of betweenness centrality\n",
    "            p = os.path.join(path, f)\n",
    "            between.append(p)\n",
    "            pass\n",
    "        else:\n",
    "            p = os.path.join(path, f)\n",
    "            edge_index.append(p)\n",
    "\n",
    "    between.sort()\n",
    "    edge_index.sort()\n",
    "    \n",
    "    return edge_index, between\n",
    "    \n",
    "    \n",
    "synthetic, between = load_data(setting.data_synthetic)\n",
    "yt, yt_score = load_data(setting.data_youtube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def split_data(path, x, y, replace=False):\n",
    "    if os.path.exists(path) and replace:\n",
    "        pass\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15)\n",
    "\n",
    "        split = {\n",
    "            \"X_train\": X_train,\n",
    "            \"X_valid\": X_valid,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\": y_train,\n",
    "            \"y_valid\": y_valid,\n",
    "            \"y_test\": y_test\n",
    "        }\n",
    "\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(split, f)\n",
    "            \n",
    "split_data(path=setting.data_split, x=synthetic, y=between)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cvt 2 dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "executionInfo": {
     "elapsed": 893,
     "status": "error",
     "timestamp": 1615282795672,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "GJrGQmiUxRGX",
    "outputId": "81d8b6cb-5008-47d8-baf4-1156d70e07fc"
   },
   "outputs": [],
   "source": [
    "def to_dataloader(x, y, batch):\n",
    "    \n",
    "    data_list = []\n",
    "    for index, f in enumerate(x):\n",
    "        edge_index = torch_geometric.io.read_txt_array(f, dtype=torch.long)\n",
    "        edge_index = edge_index.t().contiguous()\n",
    "        edge_index = utils.to_undirected(edge_index)\n",
    "\n",
    "        row, col = edge_index  \n",
    "        deg = utils.degree(col) # must use col to get degree, why?\n",
    "        deg = deg.numpy()  \n",
    "\n",
    "        vertice = []\n",
    "        for d in deg:\n",
    "            vertice.append([d, 1, 1])\n",
    "        vertice = np.array(vertice, dtype=np.float)\n",
    "        vertice = torch.from_numpy(vertice)\n",
    "\n",
    "        ### between centrality\n",
    "        bcs = []\n",
    "        bc = torch_geometric.io.read_txt_array(y[index], dtype=torch.double)\n",
    "        bc = bc.t().contiguous()\n",
    "        row, col = bc\n",
    "        bc = col\n",
    "        bc = bc.numpy()\n",
    "        \n",
    "        bcs = torch.from_numpy(\n",
    "                    np.array([[b] for b in bc], dtype=np.float))\n",
    "\n",
    "        data = Data(x=vertice, edge_index=edge_index, y=bcs)\n",
    "        data_list.append(data)\n",
    "\n",
    "    loader = DataLoader(data_list, batch_size=batch)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cvt 2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_data(x, y):\n",
    "    edge_index = torch_geometric.io.read_txt_array(x, dtype=torch.long)\n",
    "    edge_index = edge_index.t().contiguous()\n",
    "    edge_index = utils.to_undirected(edge_index)\n",
    "\n",
    "    row, col = edge_index  \n",
    "    deg = utils.degree(col) # must use col to get degree, why?\n",
    "    deg = deg.numpy()  \n",
    "\n",
    "    vertice = []\n",
    "    for d in deg:\n",
    "        vertice.append([d, 1, 1])\n",
    "    vertice = np.array(vertice, dtype=np.float)\n",
    "    vertice = torch.from_numpy(vertice)\n",
    "\n",
    "    ### between centrality\n",
    "    bcs = []\n",
    "    bc = torch_geometric.io.read_txt_array(y, dtype=torch.double)\n",
    "    bc = bc.t().contiguous()\n",
    "    row, col = bc\n",
    "    bc = col\n",
    "    bc = bc.numpy()\n",
    "    bcs = torch.from_numpy(\n",
    "            np.array([[b] for b in bc], dtype=np.float))\n",
    "\n",
    "    data = Data(x=vertice, edge_index=edge_index, y=bcs)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(setting.data_split, 'r')\n",
    "data_split = json.load(f)\n",
    "\n",
    "X_train = data_split[\"X_train\"]\n",
    "X_valid = data_split[\"X_valid\"]\n",
    "X_test = data_split[\"X_test\"]\n",
    "y_train = data_split[\"y_train\"]\n",
    "y_valid = data_split[\"y_valid\"]\n",
    "y_test = data_split[\"y_test\"]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = to_dataloader(X_train, y_train, batch=1)\n",
    "valid_loader = to_dataloader(X_valid, y_valid, batch=1)\n",
    "test_loader = to_dataloader(X_test, y_test, batch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loader = to_dataloader(synthetic, between, batch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use YT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_loader = to_dataloader(yt, yt_score, batch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jh1T_INgi8Ql"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting.params_drbc = dict(\n",
    "    # according to source paper\n",
    "    encoder_params = dict(\n",
    "        c = 3,\n",
    "        p = 128,\n",
    "        num_layers = 5,\n",
    "        device = setting.device\n",
    "    ),\n",
    "    decoder_params = dict(\n",
    "        p = 128,\n",
    "        q = 64\n",
    "    )\n",
    ")\n",
    "\n",
    "# setting.params_node2vec = dict(\n",
    "#     edge_index, \n",
    "#     embedding_dim, \n",
    "#     walk_length = 10, \n",
    "#     context_size,\n",
    "#     p = 1,\n",
    "#     q = 2\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "gcEf-tUaqDVa"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.typing import Adj, OptTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "error",
     "timestamp": 1615203940879,
     "user": {
      "displayName": "Q56094077陳香君",
      "photoUrl": "",
      "userId": "10727804849868825735"
     },
     "user_tz": -480
    },
    "id": "P5EzKoYr7SGL",
    "outputId": "5504fb67-0455-4af0-a697-930410895a70"
   },
   "outputs": [],
   "source": [
    "class Encoder(MessagePassing):\n",
    "    def __init__(self, c, p, num_layers, device, aggr=\"add\"):\n",
    "        super(Encoder, self).__init__(aggr=aggr)\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.w_0 = nn.Linear(in_features=c, out_features=p).double()\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.rnn = nn.GRUCell(p, p).double()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        \n",
    "        # compute dgree\n",
    "        row, col = edge_index\n",
    "        deg = utils.degree(col)\n",
    "        deg = torch.add(deg, 1)\n",
    "        deg_inv_sqrt = torch.pow(deg, -0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        \n",
    "        \n",
    "        # h_0 = x\n",
    "\n",
    "        # h_1\n",
    "        x = self.w_0(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        \n",
    "        h_s = [x]\n",
    "        \n",
    "        for i in range(self.num_layers-1):\n",
    "            # internally calls the message(), aggregate() and update() functions\n",
    "            x = self.propagate(edge_index, x=x, norm=norm)\n",
    "            h_s.append(x)\n",
    "        \n",
    "        h_s = torch.stack(h_s, dim=-1)\n",
    "        # Use torch.max to replace max_pooling\n",
    "        z, _ = torch.max(h_s, dim=-1)\n",
    "        # z = global_max_pool(h_s, torch.tensor([0], dtype=torch.long).to(self.device))\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def message(self, x_j, norm: OptTensor):\n",
    "        \"\"\"      \n",
    "        In addition, tensors passed to propagate() can be mapped to the respective nodes i and j \n",
    "        by appending _i or _j to the variable name, .e.g. x_i and x_j. \n",
    "        Note that we generally refer to i as the central nodes that aggregates information, \n",
    "        and refer to j as the neighboring nodes, since this is the most common notation.\n",
    "        \"\"\"\n",
    "  \n",
    "        return x_j if norm is None else norm.view(-1, 1) * x_j\n",
    "    \n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        \"\"\"        \n",
    "        Takes in the output of aggregation as first argument \n",
    "        and any argument which was initially passed to propagate().\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.rnn(x, aggr_out)\n",
    "        x = F.normalize(x, p=2, dim=1) \n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, p, q):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.w_4 = nn.Linear(in_features=p, out_features=q).double()\n",
    "        self.w_5 = nn.Linear(in_features=q, out_features=1).double()\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = self.w_4(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.w_5(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrBC(nn.Module):\n",
    "    def __init__(self, encoder_params, decoder_params):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(**encoder_params)\n",
    "        self.decoder = Decoder(**decoder_params)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        \n",
    "        z = self.encoder(data)\n",
    "        \n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BC_node2vec(nn.Module):\n",
    "    \n",
    "    def __init__(self, node2vec_params):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.node2vec = Node2Vec(**node2vec_params)\n",
    "        self.mlp = nn.Linear(in_features=128, out_features=1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        \n",
    "        x = self.node2vec(data)\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvoodu8ki_Cu"
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath, device, **params):\n",
    "\n",
    "    if \"node2vec\" in filepath:\n",
    "        model = BC_node2vec(**params[\"node2vec\"])\n",
    "    \n",
    "    else:\n",
    "        model = DrBC(**params[\"drbc\"])\n",
    "    \n",
    "    model = model.to(setting.device)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        print(\"pretrained finded\")\n",
    "        checkpoint = torch.load(filepath)\n",
    "        model.load_state_dict(checkpoint['model_stat'])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_stat'])\n",
    "\n",
    "    else:\n",
    "        print(\"use a new optimizer\")\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top k %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n(model, data, k):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        data = data.to(setting.device)\n",
    "\n",
    "        bc_gt = data.y\n",
    "        bc_gt = torch.reshape(bc_gt, (-1, ))\n",
    "\n",
    "        bc_pr = model(data)\n",
    "\n",
    "        bc_gt = bc_gt.squeeze().to(setting.device)\n",
    "        bc_pr = bc_pr.squeeze()\n",
    "\n",
    "        gt_value, gt_indice = torch.topk(bc_gt, k)\n",
    "        pr_value, pr_indice = torch.topk(bc_pr, k)\n",
    "\n",
    "        gt_indice = set(gt_indice.cpu().numpy())\n",
    "        pr_indice = set(pr_indice.cpu().numpy())\n",
    "\n",
    "        intersect = len(gt_indice & pr_indice)\n",
    "        top = intersect/k\n",
    "            \n",
    "       \n",
    "\n",
    "        return top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tau Kendal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def tau_distance(model, data):\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    " \n",
    "        data = data.to(setting.device)\n",
    "\n",
    "        bc_gt = data.y\n",
    "        bc_gt = torch.reshape(bc_gt, (-1, ))\n",
    "\n",
    "        bc_pr = model(data)\n",
    "\n",
    "        bc_gt = bc_gt.squeeze().cpu().numpy()\n",
    "        bc_pr = bc_pr.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "        tau, p_value = stats.kendalltau(bc_gt, bc_pr)\n",
    "       \n",
    "\n",
    "    return tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data, nodes_cnt):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        data = data.to(setting.device)\n",
    "        bc_pr = model(data)\n",
    "\n",
    "        bc_gt = data.y\n",
    "        bc_gt = torch.reshape(bc_gt, (-1, ))\n",
    "\n",
    "        # random sample 5|V| nodes\n",
    "        src = (torch.rand(nodes_cnt * 5) * (nodes_cnt-1)).long()\n",
    "        det = (torch.rand(nodes_cnt * 5) * (nodes_cnt-1)).long()\n",
    "\n",
    "        y_gt = (bc_gt[det] - bc_gt[src]).squeeze().to(setting.device)\n",
    "        y_pr = (bc_pr[det] - bc_pr[src]).squeeze()\n",
    "\n",
    "        y_gt = nn.Sigmoid()(y_gt)\n",
    "        y_pr = nn.Sigmoid()(y_pr)\n",
    "\n",
    "        loss = nn.BCELoss(reduction=\"sum\")(y_pr, y_gt)\n",
    "        \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_networkx(G):\n",
    "    r\"\"\"Converts a :obj:`networkx.Graph` or :obj:`networkx.DiGraph` to a\n",
    "    :class:`torch_geometric.data.Data` instance.\n",
    "\n",
    "    Args:\n",
    "        G (networkx.Graph or networkx.DiGraph): A networkx graph.\n",
    "    \"\"\"\n",
    "\n",
    "    G = nx.convert_node_labels_to_integers(G)\n",
    "    G = G.to_directed() if not nx.is_directed(G) else G\n",
    "    edge_index = torch.LongTensor(list(G.edges)).t().contiguous()\n",
    "   \n",
    "    data = {}\n",
    "\n",
    "    for i, (_, feat_dict) in enumerate(G.nodes(data=True)):\n",
    "        for key, value in feat_dict.items():\n",
    "           \n",
    "            data[str(key)] = [value] if i == 0 else data[str(key)] + [value]\n",
    "\n",
    "    for i, (_, _, feat_dict) in enumerate(G.edges(data=True)):\n",
    "        for key, value in feat_dict.items():\n",
    "            data[str(key)] = [value] if i == 0 else data[str(key)] + [value]\n",
    "\n",
    "    for key, item in data.items():\n",
    "        try:\n",
    "            data[key] = torch.tensor(item)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    data['edge_index'] = edge_index.view(2, -1)\n",
    "    data['x'] = torch.from_numpy(\n",
    "        np.array( [ [G.degree[i], 1, 1] for i in G.nodes()], dtype=np.float ) )\n",
    "    data['y'] = torch.from_numpy(\n",
    "        np.array( [ [b] for b in betweenness ] , dtype=np.float) )\n",
    "    data = torch_geometric.data.Data.from_dict(data)\n",
    "    data.num_nodes = G.number_of_nodes()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 39966], x=[5000, 3], y=[5000, 1])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use a new optimizer\n"
     ]
    }
   ],
   "source": [
    "model, optimizer = load_checkpoint(\n",
    "                    setting.weight_drbc,\n",
    "                    setting.device,\n",
    "                    drbc = setting.params_drbc,\n",
    "                    node2vec = setting.params_node2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Train: loss = 17327.332114314017, top 1 = 0.04, top 5 = 0.14, top 10 = 0.226, kendal = 0.4987872774554911\n",
      "Valid: loss = 17328.707151546227, top 1 = 0.0, top 5 = 0.0014666666666666671, top 10 = 0.006733333333333336, kendal = -0.4436868813762753\n",
      "\n",
      "Epoch: 2\n",
      "Train: loss = 17322.64059610264, top 1 = 0.02, top 5 = 0.076, top 10 = 0.168, kendal = 0.4957549909981997\n",
      "Valid: loss = 17328.7187175994, top 1 = 0.0, top 5 = 0.0014666666666666671, top 10 = 0.007400000000000001, kendal = -0.4365439647929587\n",
      "\n",
      "Epoch: 3\n",
      "Train: loss = 17318.907033099033, top 1 = 0.04, top 5 = 0.084, top 10 = 0.194, kendal = 0.49979275855171035\n",
      "Valid: loss = 17328.732307741277, top 1 = 0.0, top 5 = 0.0014666666666666671, top 10 = 0.007466666666666667, kendal = -0.4303130759485231\n"
     ]
    }
   ],
   "source": [
    "nodes_cnt = 5000\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "train_info = {\n",
    "    \"bce\": [],\n",
    "    \"top1\": [],\n",
    "    \"top5\": [],\n",
    "    \"top10\": [],\n",
    "    \"kendal\": []\n",
    "}\n",
    "\n",
    "valid_info = {\n",
    "    \"bce\": [],\n",
    "    \"top1\": [],\n",
    "    \"top5\": [],\n",
    "    \"top10\": [],\n",
    "    \"kendal\": []\n",
    "}\n",
    "\n",
    "top_10 = 0.0\n",
    "top_5 = 0.0\n",
    "top_1 = 0.0\n",
    "\n",
    "for epoch in range(setting.epochs):\n",
    "    \n",
    "    # Draw network G from distribution D (like the power-law model)\n",
    "    G = nx.generators.random_graphs.powerlaw_cluster_graph(n=nodes_cnt, m=4, p=0.05)\n",
    "    # Calculate each node’s exact BC value bv, ∀v ∈ V\n",
    "    betweenness = nx.algorithms.centrality.betweenness_centrality(G)\n",
    "    \n",
    "    # Convert networkx.Graph to Pyg Data\n",
    "    pyg_data = from_networkx(G)\n",
    "    print(\"\\nEpoch: {}\".format(epoch+1))\n",
    "    \n",
    "    # Convert betweenness dict to list\n",
    "    between_list = list(betweenness.values())\n",
    "\n",
    "    \n",
    "    ### Start training\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pyg_data = pyg_data.to(setting.device)\n",
    "    bc_pr = model(pyg_data)\n",
    "\n",
    "    bc_gt = pyg_data.y\n",
    "#     bc_gt = np.array(bc_gt)\n",
    "#     bc_gt = torch.from_numpy(bc_gt)\n",
    "    bc_gt = torch.reshape(bc_gt, (-1, ))\n",
    "\n",
    "    # random sample 5|V| nodes\n",
    "    src = (torch.rand(25000) * 4999).long()\n",
    "    det = (torch.rand(25000) * 4999).long()\n",
    "\n",
    "    y_gt = (bc_gt[det] - bc_gt[src]).squeeze().to(setting.device)\n",
    "    y_pr = (bc_pr[det] - bc_pr[src]).squeeze()\n",
    "\n",
    "    y_gt = nn.Sigmoid()(y_gt)\n",
    "    y_pr = nn.Sigmoid()(y_pr)\n",
    "\n",
    "    loss = nn.BCELoss(reduction=\"sum\")(y_pr, y_gt)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    ### Evaluation:- Train\n",
    "    top1 = top_n(model, pyg_data, k=int(nodes_cnt * 1 / 100))\n",
    "    top5 = top_n(model, pyg_data, k=int(nodes_cnt * 5 / 100))\n",
    "    top10 = top_n(model, pyg_data, k=int(nodes_cnt * 10 / 100))\n",
    "    kendal = tau_distance(model, pyg_data)\n",
    "\n",
    "    print(\"Train: loss = {}, top 1 = {}, top 5 = {}, top 10 = {}, kendal = {}\".format(\n",
    "            loss.item(),\n",
    "            top1,\n",
    "            top5,\n",
    "            top10,\n",
    "            kendal\n",
    "    ))\n",
    "\n",
    "    train_info[\"bce\"].append(loss.item())\n",
    "    train_info[\"top1\"].append(top1)\n",
    "    train_info[\"top5\"].append(top5)\n",
    "    train_info[\"top10\"].append(top10)\n",
    "    train_info[\"kendal\"].append(kendal)\n",
    "\n",
    "    with open(setting.train_info_p, 'w') as f:\n",
    "        json.dump(train_info, f)\n",
    "\n",
    "\n",
    "\n",
    "    ### Evaluation:- Synthetic\n",
    "    bce_l = []\n",
    "    top1_l = []\n",
    "    top5_l = []\n",
    "    top10_l = []\n",
    "    kendal_l = []\n",
    "\n",
    "    for data in all_loader:\n",
    "        bce_l.append(eval_model(model, data, nodes_cnt))\n",
    "        top1_l.append(top_n(model, data, k=int(nodes_cnt * 1 / 100)))\n",
    "        top5_l.append(top_n(model, data, k=int(nodes_cnt * 5 / 100)))\n",
    "        top10_l.append(top_n(model, data, k=int(nodes_cnt * 10 / 100)))\n",
    "        kendal_l.append(tau_distance(model, data))\n",
    "        \n",
    "    bce = sum(bce_l)/len(bce_l)\n",
    "    top1 = sum(top1_l)/len(top1_l)\n",
    "    top5 = sum(top5_l)/len(top5_l)\n",
    "    top10 = sum(top10_l)/len(top10_l)\n",
    "    kendal = sum(kendal_l)/len(kendal_l)\n",
    "        \n",
    "    print(\"Valid: loss = {}, top 1 = {}, top 5 = {}, top 10 = {}, kendal = {}\".format(\n",
    "        bce,\n",
    "        top1,\n",
    "        top5,\n",
    "        top10,\n",
    "        kendal\n",
    "    ))\n",
    "\n",
    "    valid_info[\"bce\"].append(bce)\n",
    "    valid_info[\"top1\"].append(top1)\n",
    "    valid_info[\"top5\"].append(top5)\n",
    "    valid_info[\"top10\"].append(top10)\n",
    "    valid_info[\"kendal\"].append(kendal)\n",
    "\n",
    "    with open(setting.val_info_p, 'w') as f:\n",
    "        json.dump(valid_info, f)\n",
    "        \n",
    "    \n",
    "    if top10 > top_10:\n",
    "        checkpoint = {\n",
    "            'model_stat': model.state_dict(),\n",
    "            'optimizer_stat': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, setting.weight_drbc)\n",
    "        top_10 = top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(setting.train_info_p, 'r') as train_info:\n",
    "    \n",
    "    train = json.load(train_info)\n",
    "\n",
    "    epochs = setting.epochs\n",
    "    keys = list(train.keys())\n",
    "\n",
    "    x = np.linspace(1, epochs, epochs)\n",
    "    \n",
    "    ### plot bce loss and mean top N %\n",
    "    fig, axs = plt.subplots(len(keys), figsize=(25, 4 * len(keys)))\n",
    "    for index, ax in enumerate(axs):\n",
    "        key = keys[index]\n",
    "        \n",
    "        if key == \"bce\":\n",
    "            ax.plot(x, train[key], color=\"blue\")\n",
    "        else:\n",
    "            y = [sum(top)/len(top) for top in train[key]]\n",
    "            ax.plot(x, y, color=\"blue\")\n",
    "        \n",
    "        ax.set_title(key)\n",
    "        ax.grid()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(setting.result_plt_p, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkit as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nk.readGraph(\"/hw1_data/Synthetic/5000/0.txt\", nk.Format.EdgeListTabZero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RK (DIAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ApproxBetweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = nk.centrality.ApproxBetweenness(G, epsilon=0.1)\n",
    "ab.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 10 most central nodes according to betweenness are then \n",
    "ab.ranking()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KADABRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize algorithm \n",
    "kadabra = nk.centrality.KadabraBetweenness(G, 0.05, 0.8) \n",
    "kadabra.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 10 most central nodes according to betweenness are then \n",
    "kadabra.ranking()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-BC (KPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbc = nk.centrality.KPathCentrality(G, alpha=0.2, k=0)\n",
    "kbc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbc.ranking()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
